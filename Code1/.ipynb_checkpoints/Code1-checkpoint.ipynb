{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "contrary-bruce",
   "metadata": {},
   "source": [
    "<center><b>In the name of God</b></center>\n",
    "\n",
    "<b>Course</b>: Machine Learning\n",
    "<br>\n",
    "<b>Description:</b> HomeWork 2 | Question 1\n",
    "<br>\n",
    "<b>Developer</b>: Alireza Mazochi (400131075)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-player",
   "metadata": {},
   "source": [
    "# Dataset Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-dependence",
   "metadata": {},
   "source": [
    "<b>Name</b>: Heart Disease Dataset<br>\n",
    "<b>Refrence</b>: https://www.kaggle.com/johnsmith88/heart-disease-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-secret",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "This data set dates from 1988 and consists of four databases: Cleveland, Hungary, Switzerland, and Long Beach V. It contains 76 attributes, including the predicted attribute, but all published experiments refer to using a subset of 14 of them. The \"target\" field refers to the presence of heart disease in the patient. It is integer valued 0 = no disease and 1 = disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-hormone",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "<nl>\n",
    "    <li>age: age in years</li>\n",
    "    <li>sex: (1 = male; 0 = female)</li>\n",
    "    <li>cp: chest pain type (4 values)</li>\n",
    "    <li>restcg: resting blood pressure (in mm Hg on admission to the hospital)</li>\n",
    "    <li>chol: serum cholestoral in mg/dl</li>\n",
    "    <li>fbs: fasting blood sugar > 120 mg/dl</li>\n",
    "    <li>restecg: resting electrocardiographic results (values 0,1,2)</li>\n",
    "    <li>thalach: maximum heart rate achieved</li>\n",
    "    <li>exang: exercise induced angina(1 = yes; 0 = no)</li>\n",
    "    <li>oldpeak: ST depression induced by exercise relative to rest</li>\n",
    "    <li>slope: the slope of the peak exercise ST segment</li>\n",
    "    <li>ca: number of major vessels (0-3) colored by flourosopy</li>\n",
    "    <li>thal: 0 = normal; 1 = fixed defect; 2 = reversable defect</li>\n",
    "</nl>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-gabriel",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "equivalent-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Allowed Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-spank",
   "metadata": {},
   "source": [
    "# Load and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "classical-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "manual-still",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0      52    1   0       125   212    0        1      168      0      1.0   \n",
       "1      53    1   0       140   203    1        0      155      1      3.1   \n",
       "2      70    1   0       145   174    0        1      125      1      2.6   \n",
       "3      61    1   0       148   203    0        1      161      0      0.0   \n",
       "4      62    0   0       138   294    1        1      106      0      1.9   \n",
       "...   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "1020   59    1   1       140   221    0        1      164      1      0.0   \n",
       "1021   60    1   0       125   258    0        0      141      1      2.8   \n",
       "1022   47    1   0       110   275    0        0      118      1      1.0   \n",
       "1023   50    0   0       110   254    0        0      159      0      0.0   \n",
       "1024   54    1   0       120   188    0        1      113      0      1.4   \n",
       "\n",
       "      slope  ca  thal  target  \n",
       "0         2   2     3       0  \n",
       "1         0   0     3       0  \n",
       "2         0   0     3       0  \n",
       "3         2   1     3       0  \n",
       "4         1   3     2       0  \n",
       "...     ...  ..   ...     ...  \n",
       "1020      2   0     2       1  \n",
       "1021      1   1     3       0  \n",
       "1022      1   1     2       0  \n",
       "1023      2   0     2       1  \n",
       "1024      1   1     3       0  \n",
       "\n",
       "[1025 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-elimination",
   "metadata": {},
   "source": [
    "# Discreate and Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "velvet-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_features = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"ca\", \"thal\"]\n",
    "continuous_features = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "binary-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some checking\n",
    "for feature in discrete_features:\n",
    "    if len(set(data[feature].values)) > 5:\n",
    "        print(set(data[feature].values))\n",
    "        raise Exception(f\"It seems to feature {feature} isn't a discrete feature\")\n",
    "        \n",
    "for feature in continuous_features:\n",
    "    if len(set(data[feature].values)) < 20:\n",
    "        print(set(data[feature].values))\n",
    "        raise Exception(f\"It seems to feature {feature} isn't a continous feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-fifth",
   "metadata": {},
   "source": [
    "# Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broke-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data.head(int(0.8*len(data)))\n",
    "data_test = data.tail(len(data) - int(0.8*len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "employed-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_x = data_train.drop(columns=[\"target\"])\n",
    "data_train_y = data_train[[\"target\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-arabic",
   "metadata": {},
   "source": [
    "# Prior Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "infectious-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pacific-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_prior = np.zeros(2)\n",
    "for class_ in classes:\n",
    "    p_prior[class_] = len(data_train_y[data_train_y[\"target\"]==class_]) / len(data_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-scoop",
   "metadata": {},
   "source": [
    "# Likelihood Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "respective-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_likelihood_discrete = []\n",
    "discrete_features_value_number = dict()\n",
    "\n",
    "for class_ in classes:\n",
    "    p_likelihood_discrete.append(dict())\n",
    "    for feature in discrete_features:\n",
    "        discrete_features_value_number[feature] = len(set(data[feature].values))\n",
    "        p_likelihood_discrete[class_][feature] = np.zeros(discrete_features_value_number[feature])\n",
    "    \n",
    "for class_ in classes:\n",
    "    data_class = data_train[data_train[\"target\"]==class_]\n",
    "    for feature in discrete_features:\n",
    "        for value in range(discrete_features_value_number[feature]):\n",
    "            p_likelihood_discrete[class_][feature][value] = len(data_class[data_class[feature]==value]) / len(data_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "grand-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_likelihood_continuous_independent = []\n",
    "\n",
    "for class_ in classes:\n",
    "    data_class = data_train[data_train[\"target\"]==class_]\n",
    "\n",
    "    p_likelihood_continuous_independent.append(dict())\n",
    "    for feature in continuous_features:\n",
    "        p_likelihood_continuous_independent[class_][feature] = {\"mean\": data_class[feature].mean(), \"var\": data_class[feature].var()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "coastal-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_likelihood_continuous_dependent = []\n",
    "\n",
    "for class_ in classes:\n",
    "    data_class = data_train[data_train[\"target\"]==class_]\n",
    "    \n",
    "    p_likelihood_continuous_dependent.append({\"mean\": data_class[continuous_features].mean().values, \"sigma\": data_class[continuous_features].cov()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "enormous-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_discrete(class_, feature, value):\n",
    "    return math.log(p_likelihood_discrete[class_][feature][int(value)])\n",
    "\n",
    "def p_continuous_independent(class_, feature, value):\n",
    "    mean = p_likelihood_continuous_independent[class_][feature][\"mean\"]\n",
    "    var = p_likelihood_continuous_independent[class_][feature][\"var\"]\n",
    "    p = 1/((2*math.pi*var)**0.5) * (math.exp((-(value-mean)**2)/(2*var)))\n",
    "    \n",
    "    return math.log(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-fundamental",
   "metadata": {},
   "source": [
    "# A. Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-bleeding",
   "metadata": {},
   "source": [
    "# B. NaÃ¯ve Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "silent-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(test_item, ignore_feature_list=[]):\n",
    "    p_list = []\n",
    "    for class_ in classes:\n",
    "        p = math.log(p_prior[class_])\n",
    "        for feature in discrete_features:\n",
    "            if feature not in ignore_feature_list:\n",
    "                p += p_discrete(class_, feature, test_item[feature])\n",
    "\n",
    "        for feature in continuous_features:\n",
    "            if feature not in ignore_feature_list:\n",
    "                p += p_continuous_independent(class_, feature, test_item[feature])\n",
    "        \n",
    "        p_list.append(p)\n",
    "    \n",
    "    if p_list[0]>p_list[1]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-horizontal",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "innovative-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_evaluation(true_list, predict_list):\n",
    "    \"\"\"\n",
    "    Report several evaluation metrics and the confusion matrix\n",
    "    \n",
    "    :param true_list: list of true labels\n",
    "    :param predict_list: list of predict labels\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(true_list, predict_list)}\")\n",
    "    print(f\"Accuracy = {round(accuracy_score(true_list, predict_list)*100, 2)}%\")\n",
    "    print(f\"Recall = {round(recall_score(true_list, predict_list)*100, 2)}%\")\n",
    "    print(f\"Precision = {round(precision_score(true_list, predict_list)*100, 2)}%\")\n",
    "    print(f\"F1 = {round(f1_score(true_list, predict_list)*100, 2)}%\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-trial",
   "metadata": {},
   "source": [
    "## All Features (Part b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "subjective-building",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[83 20]\n",
      " [23 79]]\n",
      "Accuracy = 79.02%\n",
      "Recall = 77.45%\n",
      "Precision = 79.8%\n",
      "F1 = 78.61%\n"
     ]
    }
   ],
   "source": [
    "# Test Part\n",
    "true_list = []\n",
    "predict_list = []\n",
    "for indexm, test_item in data_test.iterrows():\n",
    "    true_list.append(naive_bayes(test_item))\n",
    "    predict_list.append(test_item[\"target\"])\n",
    "\n",
    "deep_evaluation(true_list, predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "twenty-independence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[333  52]\n",
      " [ 60 375]]\n",
      "Accuracy = 86.34%\n",
      "Recall = 86.21%\n",
      "Precision = 87.82%\n",
      "F1 = 87.01%\n"
     ]
    }
   ],
   "source": [
    "# Train Part\n",
    "true_list = []\n",
    "predict_list = []\n",
    "for indexm, test_item in data_train.iterrows():\n",
    "    true_list.append(naive_bayes(test_item))\n",
    "    predict_list.append(test_item[\"target\"])\n",
    "\n",
    "deep_evaluation(true_list, predict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-reproduction",
   "metadata": {},
   "source": [
    "## Remove Some Features (Part c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "vocational-lying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[83 19]\n",
      " [23 80]]\n",
      "Accuracy = 79.51%\n",
      "Recall = 77.67%\n",
      "Precision = 80.81%\n",
      "F1 = 79.21%\n"
     ]
    }
   ],
   "source": [
    "# Test Part\n",
    "true_list = []\n",
    "predict_list = []\n",
    "for indexm, test_item in data_test.iterrows():\n",
    "    true_list.append(naive_bayes(test_item, ignore_feature_list=[\"chol\"]))\n",
    "    predict_list.append(test_item[\"target\"])\n",
    "\n",
    "deep_evaluation(true_list, predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "practical-boulder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[333  50]\n",
      " [ 60 377]]\n",
      "Accuracy = 86.59%\n",
      "Recall = 86.27%\n",
      "Precision = 88.29%\n",
      "F1 = 87.27%\n"
     ]
    }
   ],
   "source": [
    "# Train Part\n",
    "true_list = []\n",
    "predict_list = []\n",
    "for indexm, test_item in data_train.iterrows():\n",
    "    true_list.append(naive_bayes(test_item, ignore_feature_list=[\"chol\"]))\n",
    "    predict_list.append(test_item[\"target\"])\n",
    "\n",
    "deep_evaluation(true_list, predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "loaded-creation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[84 20]\n",
      " [22 79]]\n",
      "Accuracy = 79.51%\n",
      "Recall = 78.22%\n",
      "Precision = 79.8%\n",
      "F1 = 79.0%\n"
     ]
    }
   ],
   "source": [
    "# Test Part\n",
    "true_list = []\n",
    "predict_list = []\n",
    "for indexm, test_item in data_test.iterrows():\n",
    "    true_list.append(naive_bayes(test_item, ignore_feature_list=[\"oldpeak\"]))\n",
    "    predict_list.append(test_item[\"target\"])\n",
    "\n",
    "deep_evaluation(true_list, predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "packed-baltimore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[335  62]\n",
      " [ 58 365]]\n",
      "Accuracy = 85.37%\n",
      "Recall = 86.29%\n",
      "Precision = 85.48%\n",
      "F1 = 85.88%\n"
     ]
    }
   ],
   "source": [
    "# Train Part\n",
    "true_list = []\n",
    "predict_list = []\n",
    "for indexm, test_item in data_train.iterrows():\n",
    "    true_list.append(naive_bayes(test_item, ignore_feature_list=[\"oldpeak\"]))\n",
    "    predict_list.append(test_item[\"target\"])\n",
    "\n",
    "deep_evaluation(true_list, predict_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
